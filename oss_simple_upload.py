import os
import json
import base64
import time
import hmac
import hashlib
import tempfile
import numpy as np
import torch
import torchvision.transforms.functional as F
from pathlib import Path
from urllib.parse import urlparse, quote, quote_plus
from typing import List, Optional, Union, Dict, Any, Set
from fractions import Fraction
import mimetypes
import secrets
import atexit

try:
    from Crypto.PublicKey import RSA
    from Crypto.Cipher import PKCS1_v1_5
    from Crypto import Random
except ImportError:
    from Cryptodome.PublicKey import RSA
    from Cryptodome.Cipher import PKCS1_v1_5
    from Cryptodome import Random

import alibabacloud_oss_v2 as oss
from tqdm import tqdm

# =============================================================================
# ğŸ›¡ï¸ å®‰å…¨é…ç½® - ä¸¥æ ¼é™åˆ¶ä¸Šä¼ ç›®å½•å’Œæ–‡ä»¶ç±»å‹
# =============================================================================

# ä»…å…è®¸çš„ä¸Šä¼ ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼‰
ALLOWED_UPLOAD_DIRS: List[str] = [
    "/workspace/ComfyUI/temp",
    "/data/ComfyUI/personal/output",
    "/tmp"
]

# å…è®¸çš„æ–‡ä»¶ç±»å‹ç™½åå•
ALLOWED_EXTENSIONS: Set[str] = {
    '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff',  # å›¾ç‰‡
    '.mp4', '.avi', '.mov', '.mkv', '.webm', '.m4v',            # è§†é¢‘  
    '.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a',            # éŸ³é¢‘
    '.txt', '.json', '.csv', '.md',                             # æ–‡æœ¬
    '.pdf', '.doc', '.docx', '.zip',                            # æ–‡æ¡£
    '.npz', '.npy'                                              # å®‰å…¨çš„numpyæ ¼å¼ï¼ˆæ›¿ä»£pickleï¼‰
}

# å±é™©æ–‡ä»¶ç±»å‹é»‘åå• - ç»å¯¹ç¦æ­¢ï¼ˆåŒ…æ‹¬pickleï¼ï¼‰
DANGEROUS_EXTENSIONS: Set[str] = {
    '.exe', '.bat', '.cmd', '.com', '.scr', '.msi', '.app',     # å¯æ‰§è¡Œæ–‡ä»¶
    '.sh', '.bash', '.zsh', '.ps1', '.vbs',                     # è„šæœ¬
    '.py', '.rb', '.pl', '.php', '.jsp', '.js', '.ts',          # ä»£ç æ–‡ä»¶
    '.pkl', '.pickle',                                          # âš ï¸ å±é™©åºåˆ—åŒ–æ–‡ä»¶
    '.dll', '.so', '.dylib',                                    # åŠ¨æ€é“¾æ¥åº“
    '.jar', '.war', '.class'                                    # Javaæ–‡ä»¶
}

# æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆå­—èŠ‚ï¼‰
MAX_FILE_SIZES = {
    'image': 50 * 1024 * 1024,   # 50MB
    'video': 500 * 1024 * 1024,  # 500MB  
    'audio': 100 * 1024 * 1024,  # 100MB
    'text': 10 * 1024 * 1024,    # 10MB
    'document': 100 * 1024 * 1024, # 100MB
    'default': 50 * 1024 * 1024   # 50MB
}

# =============================================================================
# ğŸ›¡ï¸ å®‰å…¨éªŒè¯å‡½æ•°
# =============================================================================

class SecurityError(Exception):
    """å®‰å…¨ç›¸å…³é”™è¯¯"""
    pass

class SecureTempFileManager:
    """å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨"""
    def __init__(self):
        self.temp_files: List[str] = []
        atexit.register(self.cleanup_all)
    
    def create_temp_file(self, prefix: str, suffix: str) -> str:
        """åˆ›å»ºå®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_fd, temp_path = tempfile.mkstemp(
                prefix=f"secure_{prefix}_",
                suffix=suffix,
                dir=tempfile.gettempdir()
            )
            os.close(temp_fd)  # ç«‹å³å…³é—­æ–‡ä»¶æè¿°ç¬¦
            
            # è®¾ç½®å®‰å…¨æƒé™ï¼ˆä»…å½“å‰ç”¨æˆ·å¯è¯»å†™ï¼‰
            try:
                os.chmod(temp_path, 0o600)
            except:
                pass  # Windowså¯èƒ½ä¸æ”¯æŒchmod
            
            self.temp_files.append(temp_path)
            return temp_path
        except Exception as e:
            print(f"ğŸš¨ åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            raise SecurityError(f"æ— æ³•åˆ›å»ºå®‰å…¨ä¸´æ—¶æ–‡ä»¶: {e}")
    
    def cleanup_file(self, file_path: str):
        """å®‰å…¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
            if file_path in self.temp_files:
                self.temp_files.remove(file_path)
        except Exception as e:
            print(f"ğŸš¨ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶"""
        for file_path in self.temp_files.copy():
            self.cleanup_file(file_path)

# å…¨å±€ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
temp_manager = SecureTempFileManager()

def validate_file_path(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•å†…"""
    try:
        abs_path = os.path.abspath(os.path.normpath(file_path))
        for allowed_dir in ALLOWED_UPLOAD_DIRS:
            allowed_abs = os.path.abspath(os.path.normpath(allowed_dir))
            if abs_path.startswith(allowed_abs + os.sep) or abs_path == allowed_abs:
                return True
        print(f"ğŸš¨ å®‰å…¨è­¦å‘Š: è·¯å¾„è¢«æ‹’ç» - {abs_path}")
        return False
    except Exception as e:
        print(f"ğŸš¨ è·¯å¾„éªŒè¯é”™è¯¯: {e}")
        return False

def validate_file_type(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶ç±»å‹æ˜¯å¦å®‰å…¨"""
    try:
        _, ext = os.path.splitext(file_path.lower())
        if ext in DANGEROUS_EXTENSIONS:
            print(f"ğŸš¨ å®‰å…¨è­¦å‘Š: å±é™©æ–‡ä»¶ç±»å‹è¢«æ‹’ç» - {ext}")
            return False
        if ext not in ALLOWED_EXTENSIONS:
            print(f"ğŸš¨ å®‰å…¨è­¦å‘Š: ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ - {ext}")
            return False
        return True
    except Exception as e:
        print(f"ğŸš¨ æ–‡ä»¶ç±»å‹éªŒè¯é”™è¯¯: {e}")
        return False

def validate_file_size(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶å¤§å°æ˜¯å¦åœ¨é™åˆ¶å†…"""
    try:
        if not os.path.exists(file_path):
            return False
        file_size = os.path.getsize(file_path)
        _, ext = os.path.splitext(file_path.lower())
        
        if ext in {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff'}:
            max_size = MAX_FILE_SIZES['image']
        elif ext in {'.mp4', '.avi', '.mov', '.mkv', '.webm', '.m4v'}:
            max_size = MAX_FILE_SIZES['video']
        elif ext in {'.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a'}:
            max_size = MAX_FILE_SIZES['audio']
        elif ext in {'.txt', '.json', '.csv', '.md'}:
            max_size = MAX_FILE_SIZES['text']
        elif ext in {'.pdf', '.doc', '.docx', '.zip'}:
            max_size = MAX_FILE_SIZES['document']
        else:
            max_size = MAX_FILE_SIZES['default']
        
        if file_size > max_size:
            print(f"ğŸš¨ å®‰å…¨è­¦å‘Š: æ–‡ä»¶è¿‡å¤§ - {file_size} bytes (é™åˆ¶: {max_size} bytes)")
            return False
        return True
    except Exception as e:
        print(f"ğŸš¨ æ–‡ä»¶å¤§å°éªŒè¯é”™è¯¯: {e}")
        return False

def perform_security_validation(file_path: str) -> None:
    """æ‰§è¡Œå®Œæ•´çš„å®‰å…¨éªŒè¯"""
    print(f"ğŸ”’ å¼€å§‹å®‰å…¨éªŒè¯: {file_path}")
    
    if not os.path.exists(file_path):
        raise SecurityError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    if not validate_file_path(file_path):
        raise SecurityError(f"æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸èŒƒå›´å†…: {file_path}")
    
    if not validate_file_type(file_path):
        raise SecurityError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path}")
    
    if not validate_file_size(file_path):
        raise SecurityError(f"æ–‡ä»¶å¤§å°è¶…å‡ºé™åˆ¶: {file_path}")
    
    print(f"âœ… å®‰å…¨éªŒè¯é€šè¿‡: {file_path}")

# å°è¯•å¯¼å…¥ç›¸å…³æ¨¡å—
try:
    from PIL import Image
    from PIL.PngImagePlugin import PngInfo
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("PIL not available, image support disabled")

try:
    import soundfile as sf
    SOUNDFILE_AVAILABLE = True
except ImportError:
    SOUNDFILE_AVAILABLE = False
    print("soundfile not available, audio support disabled")

try:
    from comfy.comfy_types import IO
    from comfy.comfy_types.node_typing import IO as NodeIO
    from comfy_api.latest import Input, InputImpl
    COMFY_TYPES_AVAILABLE = True
except ImportError:
    try:
        from comfy.comfy_types.node_typing import IO as NodeIO
        COMFY_TYPES_AVAILABLE = True
    except ImportError:
        COMFY_TYPES_AVAILABLE = False
        print("ComfyUI types not available, using fallback")

# æ•°æ®ç±»å‹å®šä¹‰
class Audio:
    def __init__(self, sample_rate: int, waveform: torch.Tensor):
        self.sample_rate = sample_rate
        self.waveform = waveform

# è¾…åŠ©å‡½æ•°
def save_image_to_temp(img_tensor: torch.Tensor, filename_prefix: str = "image", format: str = "png") -> str:
    """ğŸ›¡ï¸ å®‰å…¨åœ°ä¿å­˜å›¾ç‰‡å¼ é‡åˆ°ä¸´æ—¶æ–‡ä»¶"""
    if not PIL_AVAILABLE:
        raise ImportError("PIL is required for image support")
    
    if len(img_tensor.shape) != 3:
        raise ValueError(f"Expected 3D tensor (H, W, C), got {img_tensor.shape}")
    
    # è½¬æ¢å¼ é‡æ ¼å¼
    img_tensor = img_tensor.permute(2, 0, 1)  # HWC -> CHW
    if img_tensor.shape[0] not in (3, 4):
        raise ValueError(f"Image must have 3 or 4 channels, got {img_tensor.shape[0]}")
    
    img_tensor = img_tensor.clamp(0, 1)
    img = F.to_pil_image(img_tensor)
    
    # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
    temp_file = temp_manager.create_temp_file(filename_prefix, f".{format}")
    img.save(temp_file)
    
    return temp_file

def save_audio_to_temp(audio_data: Dict[str, Any], filename_prefix: str = "audio", format: str = "wav") -> str:
    """ğŸ›¡ï¸ å®‰å…¨åœ°ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶"""
    if not SOUNDFILE_AVAILABLE:
        raise ImportError("soundfile is required for audio support")
    
    sample_rate = audio_data.get("sample_rate")
    waveform = audio_data.get("waveform")
    
    if not sample_rate or waveform is None:
        raise ValueError("Audio data must contain 'sample_rate' and 'waveform'")
    
    # å¤„ç†waveformæ ¼å¼
    if len(waveform.shape) == 3:
        if waveform.shape[0] > 1:
            raise ValueError("Audio batch size must be 1")
        waveform = waveform[0]
    elif len(waveform.shape) == 2:
        pass
    elif len(waveform.shape) == 1:
        waveform = torch.unsqueeze(waveform, 0)
    else:
        raise ValueError(f"Invalid waveform shape: {waveform.shape}")
    
    # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
    temp_file = temp_manager.create_temp_file(filename_prefix, f".{format}")
    
    # ä¿å­˜éŸ³é¢‘
    subtype = "FLOAT" if format.lower() == "wav" else None
    sf.write(temp_file, waveform.T.numpy(), sample_rate, subtype=subtype)
    
    return temp_file

def save_video_to_temp(video_input, filename_prefix: str = "video", format: str = "mp4") -> str:
    """ğŸ›¡ï¸ å®‰å…¨åœ°ä¿å­˜è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶"""
    if not COMFY_TYPES_AVAILABLE:
        raise ImportError("ComfyUI types are required for video support")
    
    # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
    temp_file = temp_manager.create_temp_file(filename_prefix, f".{format}")
    
    # ä½¿ç”¨è§†é¢‘å¯¹è±¡çš„saveæ–¹æ³•
    video_input.save_to(temp_file, format=format)
    
    return temp_file

def save_text_to_temp(text: str, filename_prefix: str = "text", format: str = "txt") -> str:
    """ğŸ›¡ï¸ å®‰å…¨åœ°ä¿å­˜æ–‡æœ¬åˆ°ä¸´æ—¶æ–‡ä»¶"""
    # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
    temp_file = temp_manager.create_temp_file(filename_prefix, f".{format}")
    
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(text)
    
    return temp_file

hhy_key = """-----BEGIN PRIVATE KEY-----
MIIEugIBADANBgkqhkiG9w0BAQEFAASCBKQwggSgAgEAAoIBAQDJAdHcxa0Lu1OY
CS18Mb0UHD6OA4UM+0e0bcYHbxHhDqZllI2y98R53ImN9FiYxGzCF/oh+KF2LhJ+
FevsaRkH5BCBt18KHzSYSg342vRz6xnfwvQwexVRDEpF03kpdD6cmMv7dr4HpYjW
moxeWrF3ctuaeGMCCQ5gZcMZCmrCGfLPoVuyiyl/qe2B+ZsN9o0TZ03BrRgspyYA
GS/rB68trPCTiz2y25jhYfNgnPJzlube2pTGF8kixkwvTFAwkOYwfq+cnJuAl/mN
i1CTrwaDhnJgofzo8g4rpAGxgMGCZjHoAMNB5eyug/REDGBhBL6nfGZugT0ahIgc
uaWTpHMBAgMBAAECggEAB25TGqYe7aqqJmor8Z4B3UQGSsAd74b8XZLrlc+lDcC5
tXKIisXKwF3PIsWmTxb/ZY1G/rGjL/QX9Ev1i+jOf2Z+tvnvSDezPUBLHBClpgGq
dCWQGxj4xrVVa1eMIJSC4k2KiHhJQg18RaFC6FPSYN3o2REDaYJJ0xXeAJ9sRxLH
W8ljrrgFiFk4NeqPXvVoB+h+H/L4LFag93AjzOORcvQzSE09hGIMqBbwNvSRAslO
s9gyE+TLB2cZXCstrBR4MmCvDh6hE9By9IHTfoDw105SjSaNuMa4ZusOfkuW7B/r
ad0Y64FN/VnDssIzIdXwlr4FELwW50ORs0yePPefMQKBgQDi4xCyyoVGFZWG19gl
q/Cs743MtS3qmt+Y4DLNEzmAO5V2J6ZRhS6coagDsj70KXCCE5/+lhJrjfe8iu8m
Jq2u3qz7Ksy3REtb35GlRWgD0hA4rslLJB0lhUWE33TLJ+37Osj6BTBYcQfy4dLC
kmqJibjlOSeB6Ww4CM+VUi0I8QKBgQDizKKtsHgitOUeFHv3s8NZWQPdVnoUgGYv
Kfdb/eCm21vIo0Wn39/zNOs95vxU9iXXFapfVuKk0r6XbsoAAQKaASpKPd9t89oM
rQcRfhwTP+CaUAMJ8ugUs/o8kSlLK8blG8C1K5g9DxdzBxbAt9TFrsYUrEOB+lhQ
nriQN4yLEQKBgGdBs53K8XB97jkaDnLGl5f8xen+ItF8fnpSvov6TdcARvso/FZp
aFc8cvyLqH7yRRPN3qi8n9F3IOIb0M7qF21YRh1g0x4s5KcBToWK2tWySlOhqFac
Lu+egY8BK2Qx3erSTBkNN31oo5d0ErkebYH+vbkEk+hZ1TiDOgXZCknhAoGAKQW2
jxASSsTJhG1UFvOu6+RL7KcNodOvp+xBT6RWFBgtO9c8bCb0TPtPaXz0OzHimkrS
7De8+u8bhiyF4QZNwClhytfyJ+Mpl41cb++NiHXPXFoIkq4bCFOdeYMQIwaiDSK9
8ocWHEU0ipvHo8gcdj0smuSluUbc3og2/e7uPuECfwv51oZlwSV/Lw9RlCGYd6aI
7s7JQqKgO5Uuzkj1vqmq38tj8MY9ABsTrpS5vbNYNN2u6q6/vWWJpV7gd/DBvQKS
OKOj9wa2GCJkZBTx/g4pIqRLAX6rDGAH+m1IH2T48NszoUhR3wYnT31/6CcUkTtj
wHn8/YsYZz89sqcqQlw=
-----END PRIVATE KEY-----"""


def __init__(self, encrypted_config: str):
    self.encrypted_config = encrypted_config
    self.client = None
    self.config = None
    self._init_client()

def _decrypt_config(self, encrypted_config_b64: str) -> dict:
    try:
        key = RSA.import_key(hhy_key)
    except Exception as exc:
        raise ValueError(f"å¯¼å…¥å¯†é’¥å¤±è´¥: {exc}")

    cipher = PKCS1_v1_5.new(key)
    encrypted_bytes = base64.b64decode(encrypted_config_b64)
    sentinel = Random.new().read(16)
    decrypted_bytes = cipher.decrypt(encrypted_bytes, sentinel)
    if decrypted_bytes == sentinel:
        raise ValueError("æŸåçš„osså­—ç¬¦ä¸²æ•°æ®")
    try:
        return json.loads(decrypted_bytes.decode("utf-8"))
    except Exception as exc:
        raise ValueError(f"è§£å¯†åçš„JSONè§£æå¤±è´¥: {exc}")

def _init_client(self):
    try:
        cfg_dict = _decrypt_config(self, self.encrypted_config)
        cfg_upper = {str(k).upper(): v for k, v in cfg_dict.items()}
        
        self.region = cfg_upper.get("REGION")
        self.bucket_name = cfg_upper.get("BUCKET")
        self.endpoint = cfg_upper.get("ENDPOINT")
        access_key_id = cfg_upper.get("ACCESS_KEY_ID")
        access_key_secret = cfg_upper.get("ACCESS_KEY_SECRET")
        security_token = cfg_upper.get("SECURITY_TOKEN")
        
        if not all([self.region, self.bucket_name, access_key_id, access_key_secret]):
            raise ValueError("osså­—ç¬¦ä¸²ç¼ºå°‘å¿…è¦å­—æ®µ")
        
        if self.region and self.region.startswith("oss-"):
            self.region = self.region[4:]
        
        if security_token:
            credentials_provider = oss.credentials.StaticCredentialsProvider(
                access_key_id, access_key_secret, security_token
            )
        else:
            credentials_provider = oss.credentials.StaticCredentialsProvider(
                access_key_id, access_key_secret
            )
        
        cfg = oss.config.load_default()
        cfg.credentials_provider = credentials_provider
        cfg.region = self.region
        try:
            if self.endpoint:
                cfg.endpoint = self.endpoint
        except Exception:
            pass

        self.client = oss.Client(cfg)
        
    except Exception as e:
        print(f"OSSå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        raise

def upload_file_with_progress(self, local_file_path, object_name=None):
    # ğŸ›¡ï¸ æ‰§è¡Œå®‰å…¨éªŒè¯
    try:
        perform_security_validation(local_file_path)
    except SecurityError as e:
        raise SecurityError(f"ğŸš¨ ä¸Šä¼ è¢«æ‹’ç»: {e}")
    
    if not os.path.exists(local_file_path):
        raise FileNotFoundError(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")
    
    if object_name is None:
        cfg_dict = _decrypt_config(self, self.encrypted_config)
        cfg_upper = {str(k).upper(): v for k, v in cfg_dict.items()}
        key_from_config = cfg_upper.get("KEY")
        
        folder = "hhy"
        file_name = os.path.basename(local_file_path)
        
        if key_from_config:
            key_has_ext = os.path.splitext(key_from_config)[1] != ""
            if key_has_ext:
                object_name = key_from_config
            else:
                object_name = f"{folder.strip('/')}/{file_name}"
        else:
            object_name = f"{folder.strip('/')}/{file_name}"
    
    file_size = os.path.getsize(local_file_path)

    print(f"å¼€å§‹ä¸Šä¼ æ–‡ä»¶: {local_file_path}")
    print(f"ç›®æ ‡å¯¹è±¡: {object_name}")
    print(f"æ–‡ä»¶å¤§å°: {_format_file_size(self, file_size)}")
    print("-" * 50)

    PART_SIZE_BYTES = 5 * 1024 * 1024
    MAX_PART_RETRIES = 3
    RETRY_SLEEP_SECONDS = 2

    progress_bar = tqdm(total=file_size, unit='B', unit_scale=True, desc='ä¸Šä¼ è¿›åº¦', ncols=80)

    init_res = self.client.initiate_multipart_upload(
        oss.InitiateMultipartUploadRequest(bucket=self.bucket_name, key=object_name)
    )
    upload_id = init_res.upload_id

    part_number = 1
    upload_parts: List[oss.UploadPart] = []

    try:
        with open(local_file_path, 'rb') as f:
            for start in range(0, file_size, PART_SIZE_BYTES):
                size = min(PART_SIZE_BYTES, file_size - start)
                reader = oss.io_utils.SectionReader(oss.io_utils.ReadAtReader(f), start, size)

                part_last_written = 0

                def progress_fn(*args):
                    nonlocal part_last_written
                    if len(args) >= 3:
                        n = int(args[0])
                        if n > 0:
                            progress_bar.update(n)
                            part_last_written += n
                    elif len(args) == 2:
                        consumed = int(args[0])
                        delta = max(0, consumed - part_last_written)
                        if delta:
                            progress_bar.update(delta)
                            part_last_written = consumed

                attempts = 0
                while True:
                    try:
                        req = oss.UploadPartRequest(
                            bucket=self.bucket_name,
                            key=object_name,
                            upload_id=upload_id,
                            part_number=part_number,
                            body=reader,
                            progress_fn=progress_fn,
                        )
                        up_res = self.client.upload_part(req)
                        upload_parts.append(oss.UploadPart(part_number=part_number, etag=up_res.etag))
                        break
                    except Exception as e:
                        attempts += 1
                        if attempts >= MAX_PART_RETRIES:
                            raise
                        time.sleep(RETRY_SLEEP_SECONDS)

                part_number += 1

        # 2) å®Œæˆåˆ†ç‰‡
        parts_sorted = sorted(upload_parts, key=lambda p: p.part_number)
        comp_req = oss.CompleteMultipartUploadRequest(
            bucket=self.bucket_name,
            key=object_name,
            upload_id=upload_id,
            complete_multipart_upload=oss.CompleteMultipartUpload(parts=parts_sorted),
        )
        result = self.client.complete_multipart_upload(comp_req)

        if progress_bar.n < file_size:
            progress_bar.update(file_size - progress_bar.n)
        progress_bar.close()

        print("\n" + "=" * 50)
        print("ä¸Šä¼ å®Œæˆï¼(åˆ†ç‰‡ä¸Šä¼ )")
        print(f"çŠ¶æ€ç : {result.status_code}")
        print(f"è¯·æ±‚ID: {result.request_id}")
        print(f"ETag: {result.etag}")
        print(f"CRC64æ ¡éªŒç : {result.hash_crc64}")

        presigned_url = _generate_presigned_url(self, object_name)

        return {
            'status_code': result.status_code,
            'request_id': result.request_id,
            'content_md5': getattr(result, 'content_md5', ''),
            'etag': result.etag,
            'hash_crc64': result.hash_crc64,
            'version_id': getattr(result, 'version_id', None),
            'object_name': object_name,
            'presigned_url': presigned_url
        }

    except Exception as e:
        progress_bar.close()
        print(f"\nä¸Šä¼ å¤±è´¥: {e}")
        raise

def _generate_presigned_url(self, object_key, expires=3600):
    try:
        cfg_dict = _decrypt_config(self, self.encrypted_config)
        cfg_upper = {str(k).upper(): v for k, v in cfg_dict.items()}
        
        access_key_id = cfg_upper.get("ACCESS_KEY_ID")
        access_key_secret = cfg_upper.get("ACCESS_KEY_SECRET")
        security_token = cfg_upper.get("SECURITY_TOKEN")
        
        quoted_key = quote(object_key.lstrip('/'))
        host = f"oss-{self.region}.aliyuncs.com"
        expires_ts = int(time.time()) + int(expires)
        string_to_sign = f"GET\n\n\n{expires_ts}\n/{self.bucket_name}/{object_key}"
        signature = base64.b64encode(
            hmac.new(access_key_secret.encode('utf-8'), string_to_sign.encode('utf-8'), hashlib.sha1).digest()
        ).decode('utf-8')
        query = f"OSSAccessKeyId={quote_plus(access_key_id)}&Expires={expires_ts}&Signature={quote_plus(signature)}"
        if security_token:
            query += f"&security-token={quote_plus(security_token)}"
        
        presigned_url = f"https://{self.bucket_name}.{host}/{quoted_key}?{query}"
        return presigned_url
        
    except Exception as e:
        print(f"ç”Ÿæˆä¸´æ—¶URLå¤±è´¥: {e}")
        return None

def _format_file_size(self, size_bytes):
    if size_bytes == 0:
        return "0B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.2f} {size_names[i]}"


 


class ResourceToFilePaths:
    """èµ„æºè½¬æ–‡ä»¶è·¯å¾„èŠ‚ç‚¹ï¼Œå°†å„ç§èµ„æºï¼ˆå›¾ç‰‡listã€éŸ³é¢‘listç­‰ï¼‰è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨"""
    
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "resources": (NodeIO.ANY if COMFY_TYPES_AVAILABLE else "ANY", {
                    "tooltip": "èµ„æºè¾“å…¥ï¼šæ”¯æŒå›¾ç‰‡listã€éŸ³é¢‘listã€è§†é¢‘listç­‰"
                }),
            },
            "optional": {
                "filename_prefix": ("STRING", {
                    "default": "resource",
                    "tooltip": "æ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼‰"
                }),
                "output_format": (["auto", "png", "jpg", "wav", "mp4", "txt", "json"], {
                    "default": "auto",
                    "tooltip": "è¾“å‡ºæ–‡ä»¶æ ¼å¼ï¼Œautoä¸ºè‡ªåŠ¨æ£€æµ‹"
                }),
                "max_resources": ("INT", {
                    "default": 20,
                    "min": 1,
                    "max": 100,
                    "tooltip": "æœ€å¤§å¤„ç†èµ„æºæ•°é‡"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "INT", "STRING")
    RETURN_NAMES = ("file_paths", "process_log", "file_count", "file_types")
    FUNCTION = "convert_to_paths"
    CATEGORY = "hhy/oss"
    INPUT_IS_LIST = True
    OUTPUT_IS_LIST = (False, False, False, False)
    
    def _process_single_resource(self, resource, filename_prefix, index, output_format="auto"):
        """å¤„ç†å•ä¸ªèµ„æºï¼Œè¿”å›(æ–‡ä»¶è·¯å¾„, æ•°æ®ç±»å‹, ä¸´æ—¶æ–‡ä»¶è·¯å¾„)"""
        temp_file = None
        data_type = "unknown"
        format_ext = output_format if output_format != "auto" else None
        
        # ä¸ºæ¯ä¸ªèµ„æºç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        unique_prefix = f"{filename_prefix}_{index}_{int(time.time())}"
        
        # 1. æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
        if isinstance(resource, str):
            if os.path.exists(resource):
                return resource, "existing_file", None
            else:
                # å½“ä½œæ–‡æœ¬å†…å®¹å¤„ç†
                ext = format_ext or "txt"
                temp_file = save_text_to_temp(resource, unique_prefix, ext)
                return temp_file, "text", temp_file
        
        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯torch.Tensorï¼ˆå›¾ç‰‡ï¼‰
        elif isinstance(resource, torch.Tensor):
            if len(resource.shape) >= 3:
                try:
                    # å¦‚æœæ˜¯æ‰¹é‡ï¼Œå–ç¬¬ä¸€å¼ 
                    if len(resource.shape) == 4:
                        resource = resource[0]
                    ext = format_ext or "png"
                    temp_file = save_image_to_temp(resource, unique_prefix, ext)
                    return temp_file, "image", temp_file
                except Exception:
                    # ğŸš¨ å®‰å…¨ç­–ç•¥: ç¦ç”¨pickleåºåˆ—åŒ–ï¼Œæ”¹ç”¨å®‰å…¨çš„numpyæ ¼å¼
                    temp_file = temp_manager.create_temp_file(unique_prefix, ".npz")
                    try:
                        # ä½¿ç”¨numpyçš„å®‰å…¨å‹ç¼©æ ¼å¼ä»£æ›¿pickle
                        np.savez_compressed(temp_file, data=resource.cpu().numpy())
                        return temp_file, "tensor", temp_file
                    except Exception as e:
                        temp_manager.cleanup_file(temp_file)
                        raise SecurityError(f"æ— æ³•å®‰å…¨ä¿å­˜tensoræ•°æ®: {e}")
        
        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯éŸ³é¢‘å­—å…¸
        elif isinstance(resource, dict) and "sample_rate" in resource and "waveform" in resource:
            ext = format_ext or "wav"
            temp_file = save_audio_to_temp(resource, unique_prefix, ext)
            return temp_file, "audio", temp_file
        
        # 4. æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘å¯¹è±¡
        elif hasattr(resource, 'save_to'):
            try:
                ext = format_ext or "mp4"
                temp_file = save_video_to_temp(resource, unique_prefix, ext)
                return temp_file, "video", temp_file
            except Exception:
                pass
        
        # 5. æ£€æŸ¥åŸºæœ¬æ•°æ®ç±»å‹
        elif isinstance(resource, (int, float, bool)):
            content = str(resource)
            ext = format_ext or "txt"
            temp_file = save_text_to_temp(content, unique_prefix, ext)
            return temp_file, "numeric", temp_file
        
        # 6. æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨æˆ–å­—å…¸
        elif isinstance(resource, (list, dict, tuple)):
            try:
                content = json.dumps(resource, indent=2, ensure_ascii=False)
                ext = format_ext or "json"
                temp_file = save_text_to_temp(content, unique_prefix, ext)
                return temp_file, "json", temp_file
            except Exception:
                content = str(resource)
                ext = format_ext or "txt"
                temp_file = save_text_to_temp(content, unique_prefix, ext)
                return temp_file, "data", temp_file
        
        # 7. å…¶ä»–ç±»å‹
        else:
            try:
                content = json.dumps(resource, indent=2, ensure_ascii=False)
                ext = format_ext or "json"
                temp_file = save_text_to_temp(content, unique_prefix, ext)
                return temp_file, "serialized", temp_file
            except Exception:
                try:
                    content = str(resource)
                    ext = format_ext or "txt"
                    temp_file = save_text_to_temp(content, unique_prefix, ext)
                    return temp_file, "string", temp_file
                except Exception:
                    # ğŸš¨ å®‰å…¨ç­–ç•¥: ç¦ç”¨pickleåºåˆ—åŒ–ï¼Œæ‹’ç»å¤„ç†æœªçŸ¥ç±»å‹
                    raise SecurityError(
                        f"ğŸš¨ ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(resource).__name__}\n"
                        f"ä¸ºäº†å®‰å…¨ï¼Œå·²ç¦ç”¨pickleåºåˆ—åŒ–åŠŸèƒ½ã€‚\n"
                        f"æ”¯æŒçš„ç±»å‹: å­—ç¬¦ä¸²ã€å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ã€åŸºæœ¬æ•°æ®ç±»å‹ã€JSONå…¼å®¹çš„å¯¹è±¡"
                    )

    def convert_to_paths(self, resources, filename_prefix="resource", output_format="auto", max_resources=20):
        """å°†èµ„æºåˆ—è¡¨è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨"""
        try:
            # å¤„ç†è¾“å…¥å‚æ•°ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨æ ¼å¼ï¼‰
            if isinstance(filename_prefix, list):
                filename_prefix = filename_prefix[0] if filename_prefix else "resource"
            if isinstance(output_format, list):
                output_format = output_format[0] if output_format else "auto"
            if isinstance(max_resources, list):
                max_resources = max_resources[0] if max_resources else 20
            
            print(f"[ResourceToFilePaths] å¤„ç† {len(resources)} ä¸ªèµ„æºï¼Œå‰ç¼€: {filename_prefix}")
            
            file_paths = []
            process_logs = []
            file_types = []
            
            # é™åˆ¶å¤„ç†æ•°é‡
            resources_to_process = resources[:max_resources]
            
            for i, resource in enumerate(resources_to_process):
                try:
                    file_path, data_type, temp_path = self._process_single_resource(
                        resource, filename_prefix, i+1, output_format
                    )
                    
                    if file_path:
                        file_paths.append(file_path)
                        file_types.append(data_type)
                        
                        log_msg = f"èµ„æº{i+1}: {data_type} -> {os.path.basename(file_path)}"
                        process_logs.append(log_msg)
                        print(f"[ResourceToFilePaths] {log_msg}")
                    else:
                        error_msg = f"èµ„æº{i+1}: å¤„ç†å¤±è´¥"
                        process_logs.append(error_msg)
                        print(f"[ResourceToFilePaths] {error_msg}")
                        
                except Exception as e:
                    error_msg = f"èµ„æº{i+1}: å¤„ç†å¼‚å¸¸ - {str(e)}"
                    process_logs.append(error_msg)
                    print(f"[ResourceToFilePaths] {error_msg}")
            
            # ç»„åˆç»“æœ
            paths_str = "\n".join(file_paths) if file_paths else ""
            logs_str = "\n".join(process_logs)
            types_str = "\n".join(file_types) if file_types else ""
            file_count = len(file_paths)
            
            summary = f"\n=== å¤„ç†å®Œæˆ ===\næˆåŠŸ: {file_count}/{len(resources_to_process)} ä¸ªèµ„æº"
            logs_str += summary
            print(f"[ResourceToFilePaths] {summary}")
            
            return (paths_str, logs_str, file_count, types_str)
            
        except Exception as exc:
            error_msg = f"èµ„æºå¤„ç†å¤±è´¥: {str(exc)}"
            print(f"[ResourceToFilePaths] {error_msg}")
            return ("", error_msg, 0, "")


class OSSUploadFromPaths:
    """OSSæ–‡ä»¶è·¯å¾„ä¸Šä¼ èŠ‚ç‚¹ï¼Œä¸“é—¨å¤„ç†æ–‡ä»¶è·¯å¾„è¾“å…¥ï¼Œæ”¯æŒå¤šä¸ªè·¯å¾„æ‰¹é‡ä¸Šä¼ """
    
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "oss_encrypted_config": ("STRING", {
                    "multiline": False,
                    "tooltip": "åŠ å¯†çš„OSSé…ç½®å­—ç¬¦ä¸²"
                }),
                "file_paths": ("STRING", {
                    "multiline": True,
                    "tooltip": "æ–‡ä»¶è·¯å¾„è¾“å…¥ï¼Œæ¯è¡Œä¸€ä¸ªè·¯å¾„æˆ–ç”¨åˆ†å·åˆ†éš”ï¼ˆå¯è¿æ¥ResourceToFilePathsèŠ‚ç‚¹ï¼‰"
                }),
            },
            "optional": {
                "filename_prefix": ("STRING", {
                    "default": "",
                    "tooltip": "æ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨åŸæ–‡ä»¶åï¼‰"
                }),
                "max_files": ("INT", {
                    "default": 20,
                    "min": 1,
                    "max": 100,
                    "tooltip": "æœ€å¤§ä¸Šä¼ æ–‡ä»¶æ•°é‡"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING", "INT")
    RETURN_NAMES = ("urls", "upload_logs", "valid_paths", "uploaded_count")
    FUNCTION = "upload_from_paths"
    CATEGORY = "hhy/oss"
    
    def _parse_file_paths(self, file_paths_input):
        """è§£ææ–‡ä»¶è·¯å¾„è¾“å…¥ï¼Œæ”¯æŒæ¢è¡Œç¬¦å’Œåˆ†å·åˆ†éš”"""
        if not file_paths_input:
            return []
        
        # å…ˆæŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼Œå†æŒ‰åˆ†å·åˆ†å‰²
        paths = []
        lines = file_paths_input.strip().split('\n')
        for line in lines:
            line = line.strip()
            if line:
                # æŒ‰åˆ†å·åˆ†å‰²
                sub_paths = [p.strip() for p in line.split(';') if p.strip()]
                paths.extend(sub_paths)
        
        return paths
    
    def upload_from_paths(self, oss_encrypted_config, file_paths, filename_prefix="", max_files=10):
        """ä»æ–‡ä»¶è·¯å¾„æ‰¹é‡ä¸Šä¼ åˆ°OSS"""
        try:
            # è§£ææ–‡ä»¶è·¯å¾„
            paths = self._parse_file_paths(file_paths)
            
            if not paths:
                return ("", "æ²¡æœ‰æä¾›æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„", "", 0)
            
            # é™åˆ¶æ–‡ä»¶æ•°é‡
            paths = paths[:max_files]
            
            # åˆå§‹åŒ–OSSå®¢æˆ·ç«¯
            self.encrypted_config = oss_encrypted_config
            _init_client(self)
            
            results = []
            valid_paths = []
            upload_logs = []
            
            for i, file_path in enumerate(paths):
                try:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if not os.path.exists(file_path):
                        error_log = f"æ–‡ä»¶{i+1}: è·¯å¾„ä¸å­˜åœ¨ - {file_path}"
                        upload_logs.append(error_log)
                        print(f"[OSSä¸Šä¼ ] {error_log}")
                        continue
                    
                    # ğŸ›¡ï¸ æ‰§è¡Œå®‰å…¨éªŒè¯
                    try:
                        perform_security_validation(file_path)
                    except SecurityError as e:
                        error_log = f"æ–‡ä»¶{i+1}: å®‰å…¨éªŒè¯å¤±è´¥ - {os.path.basename(file_path)} | é”™è¯¯: {str(e)}"
                        upload_logs.append(error_log)
                        print(f"[OSSä¸Šä¼ ] {error_log}")
                        continue
                    
                    # ä¸Šä¼ æ–‡ä»¶ï¼ˆä½¿ç”¨åŸæ–‡ä»¶åï¼Œä¸æ·»åŠ å‰ç¼€ï¼‰
                    result = upload_file_with_progress(self, file_path)
                    
                    # ç”ŸæˆURL
                    url = result.get('presigned_url')
                    if not url:
                        object_name = result.get('object_name')
                        if getattr(self, 'endpoint', None) and self.endpoint.startswith('http'):
                            url = f"{self.endpoint.rstrip('/')}/{object_name}"
                        else:
                            url = f"https://{self.bucket_name}.oss-{self.region}.aliyuncs.com/{object_name}"
                    
                    results.append(url)
                    valid_paths.append(file_path)
                    
                    # ç”Ÿæˆæ—¥å¿—
                    log_msg = f"æ–‡ä»¶{i+1}: ä¸Šä¼ æˆåŠŸ - {os.path.basename(file_path)} | {result.get('etag', '')[:8]}..."
                    upload_logs.append(log_msg)
                    print(f"[OSSä¸Šä¼ ] {log_msg}")
                    
                except Exception as e:
                    error_log = f"æ–‡ä»¶{i+1}: ä¸Šä¼ å¤±è´¥ - {os.path.basename(file_path)} | é”™è¯¯: {str(e)}"
                    upload_logs.append(error_log)
                    print(f"[OSSä¸Šä¼ ] {error_log}")
            
            # ç»„åˆç»“æœ
            urls_str = "\n".join(results) if results else ""
            logs_str = "\n".join(upload_logs)
            paths_str = "\n".join(valid_paths)
            uploaded_count = len(results)
            
            summary_log = f"\n=== ä¸Šä¼ å®Œæˆ ===\næˆåŠŸ: {uploaded_count}/{len(paths)} ä¸ªæ–‡ä»¶"
            logs_str += summary_log
            print(f"[OSSä¸Šä¼ ] {summary_log}")
            
            return (urls_str, logs_str, paths_str, uploaded_count)
            
        except Exception as exc:
            error_msg = f"æ‰¹é‡ä¸Šä¼ å¤±è´¥: {str(exc)}"
            return ("", error_msg, "", 0)


class VideoCombineToPath:
    """è§†é¢‘åˆæˆèŠ‚ç‚¹ï¼Œå°†å›¾ç‰‡batchå’ŒéŸ³é¢‘åˆæˆä¸ºè§†é¢‘å¹¶è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE", {
                    "tooltip": "å›¾ç‰‡batchè¾“å…¥"
                }),
                "frame_rate": ("FLOAT", {
                    "default": 24.0,
                    "min": 1.0,
                    "max": 120.0,
                    "step": 0.1,
                    "tooltip": "è§†é¢‘å¸§ç‡(FPS)"
                }),
                "filename_prefix": ("STRING", {
                    "default": "video",
                    "tooltip": "è¾“å‡ºæ–‡ä»¶åå‰ç¼€"
                }),
            },
            "optional": {
                "audio": ("AUDIO", {
                    "tooltip": "éŸ³é¢‘è¾“å…¥ï¼ˆå¯é€‰ï¼‰"
                }),
                "video_format": (["mp4", "avi", "mov", "webm"], {
                    "default": "mp4",
                    "tooltip": "è§†é¢‘æ ¼å¼"
                }),
                "quality": (["high", "medium", "low"], {
                    "default": "medium",
                    "tooltip": "è§†é¢‘è´¨é‡"
                }),
                "loop_count": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 100,
                    "tooltip": "å¾ªç¯æ¬¡æ•°ï¼Œ0ä¸ºä¸å¾ªç¯"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "INT", "FLOAT")
    RETURN_NAMES = ("video_path", "process_log", "frame_count", "duration")
    FUNCTION = "combine_video"
    CATEGORY = "hhy/oss"

    def _tensor_to_pil(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºPIL Image"""
        # ç¡®ä¿tensoråœ¨CPUä¸Šä¸”ä¸ºnumpyæ ¼å¼
        if hasattr(tensor, 'cpu'):
            tensor = tensor.cpu()
        if hasattr(tensor, 'numpy'):
            tensor = tensor.numpy()
        
        # è½¬æ¢æ•°æ®ç±»å‹å’ŒèŒƒå›´
        if tensor.dtype != np.uint8:
            if tensor.max() <= 1.0:
                tensor = (tensor * 255).astype(np.uint8)
            else:
                tensor = tensor.astype(np.uint8)
        
        return Image.fromarray(tensor)

    def _save_frames_as_temp_video(self, images, frame_rate, filename_prefix, video_format, quality, audio=None):
        """ğŸ›¡ï¸ å®‰å…¨åœ°ä¿å­˜å¸§åºåˆ—ä¸ºä¸´æ—¶è§†é¢‘æ–‡ä»¶"""
        # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
        video_file = temp_manager.create_temp_file(filename_prefix, f".{video_format}")
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„è§†é¢‘ç¼–ç åº“
            try:
                import cv2
                return self._save_with_opencv(images, frame_rate, video_file, audio)
            except ImportError:
                pass
            
            try:
                import imageio
                return self._save_with_imageio(images, frame_rate, video_file, quality, audio)
            except ImportError:
                pass
            
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œä½¿ç”¨PILä¿å­˜ä¸ºGIF
            return self._save_as_gif(images, frame_rate, filename_prefix)
            
        except Exception as e:
            print(f"è§†é¢‘ä¿å­˜å¤±è´¥: {e}")
            raise

    def _save_with_opencv(self, images, frame_rate, video_file, audio=None):
        """ä½¿ç”¨OpenCVä¿å­˜è§†é¢‘"""
        import cv2
        
        # è·å–ç¬¬ä¸€å¸§çš„å°ºå¯¸
        first_frame = self._tensor_to_pil(images[0])
        width, height = first_frame.size
        
        # åˆ›å»ºè§†é¢‘ç¼–å†™å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video_file, fourcc, frame_rate, (width, height))
        
        for image_tensor in images:
            pil_image = self._tensor_to_pil(image_tensor)
            # PILè½¬OpenCVæ ¼å¼ (RGB -> BGR)
            opencv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            out.write(opencv_image)
        
        out.release()
        
        # å¦‚æœæœ‰éŸ³é¢‘ï¼Œéœ€è¦ç”¨ffmpegåˆå¹¶
        if audio is not None:
            return self._add_audio_with_ffmpeg(video_file, audio, frame_rate)
        
        return video_file

    def _save_with_imageio(self, images, frame_rate, video_file, quality, audio=None):
        """ä½¿ç”¨imageioä¿å­˜è§†é¢‘"""
        import imageio
        
        # è®¾ç½®è´¨é‡å‚æ•°
        quality_map = {"high": 9, "medium": 5, "low": 2}
        crf = quality_map.get(quality, 5)
        
        # è½¬æ¢å›¾ç‰‡ä¸ºnumpyæ•°ç»„åˆ—è¡¨
        frames = []
        for image_tensor in images:
            pil_image = self._tensor_to_pil(image_tensor)
            frames.append(np.array(pil_image))
        
        # ä¿å­˜è§†é¢‘
        imageio.mimsave(video_file, frames, fps=frame_rate, 
                       macro_block_size=None, codec='libx264', 
                       quality=crf, pixelformat='yuv420p')
        
        # å¦‚æœæœ‰éŸ³é¢‘ï¼Œéœ€è¦ç”¨ffmpegåˆå¹¶
        if audio is not None:
            return self._add_audio_with_ffmpeg(video_file, audio, frame_rate)
        
        return video_file

    def _save_as_gif(self, images, frame_rate, filename_prefix):
        """ğŸ›¡ï¸ å®‰å…¨åœ°ä¿å­˜ä¸ºGIFæ ¼å¼ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†å™¨
        gif_file = temp_manager.create_temp_file(filename_prefix, ".gif")
        
        pil_images = [self._tensor_to_pil(img) for img in images]
        duration = int(1000 / frame_rate)  # æ¯«ç§’
        
        pil_images[0].save(
            gif_file,
            save_all=True,
            append_images=pil_images[1:],
            duration=duration,
            loop=0
        )
        
        return gif_file

    def _add_audio_with_ffmpeg(self, video_file, audio, frame_rate):
        """ä½¿ç”¨ffmpegæ·»åŠ éŸ³é¢‘åˆ°è§†é¢‘"""
        try:
            import subprocess
            import shutil
            
            # æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
            if not shutil.which('ffmpeg'):
                print("ffmpegä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘åˆæˆ")
                return video_file
            
            # ğŸ›¡ï¸ åˆ›å»ºå®‰å…¨çš„ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            audio_file = temp_manager.create_temp_file("temp_audio", ".wav")
            
            # ä¿å­˜éŸ³é¢‘
            sample_rate = audio.get("sample_rate", 44100)
            waveform = audio.get("waveform")
            
            if waveform is not None:
                # è½¬æ¢waveformä¸ºnumpy
                if hasattr(waveform, 'cpu'):
                    waveform = waveform.cpu()
                if hasattr(waveform, 'numpy'):
                    waveform = waveform.numpy()
                
                # ä¿å­˜ä¸ºwavæ–‡ä»¶
                import soundfile as sf
                if len(waveform.shape) == 3 and waveform.shape[0] == 1:
                    waveform = waveform[0]  # ç§»é™¤batchç»´åº¦
                
                sf.write(audio_file, waveform.T, sample_rate)
                
                # ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
                output_file = video_file.replace('.mp4', '_with_audio.mp4')
                cmd = [
                    'ffmpeg', '-y',
                    '-i', video_file,
                    '-i', audio_file,
                    '-c:v', 'copy',
                    '-c:a', 'aac',
                    '-shortest',
                    output_file
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.remove(audio_file)
                        os.remove(video_file)
                    except:
                        pass
                    return output_file
                else:
                    print(f"ffmpegé”™è¯¯: {result.stderr}")
                    return video_file
            
        except Exception as e:
            print(f"éŸ³é¢‘åˆæˆå¤±è´¥: {e}")
        
        return video_file

    def combine_video(self, images, frame_rate, filename_prefix, audio=None, video_format="mp4", quality="medium", loop_count=0):
        """åˆæˆè§†é¢‘ä¸»å‡½æ•°"""
        try:
            # éªŒè¯è¾“å…¥
            if images is None or len(images) == 0:
                return ("", "é”™è¯¯: æ²¡æœ‰è¾“å…¥å›¾ç‰‡", 0, 0.0)
            
            frame_count = len(images)
            duration = frame_count / frame_rate
            
            print(f"[VideoCombine] å¼€å§‹åˆæˆè§†é¢‘: {frame_count}å¸§, {frame_rate}fps, æ—¶é•¿{duration:.2f}ç§’")
            
            # åˆæˆè§†é¢‘
            video_path = self._save_frames_as_temp_video(
                images, frame_rate, filename_prefix, video_format, quality, audio
            )
            
            # ç”Ÿæˆæ—¥å¿—
            log_items = [
                f"frames={frame_count}",
                f"fps={frame_rate}",
                f"duration={duration:.2f}s",
                f"format={video_format}",
                f"quality={quality}",
                f"has_audio={audio is not None}",
                f"output={os.path.basename(video_path)}"
            ]
            process_log = " | ".join(log_items)
            
            print(f"[VideoCombine] åˆæˆå®Œæˆ: {os.path.basename(video_path)}")
            
            return (video_path, process_log, frame_count, duration)
            
        except Exception as exc:
            error_msg = f"è§†é¢‘åˆæˆå¤±è´¥: {str(exc)}"
            print(f"[VideoCombine] {error_msg}")
            return ("", error_msg, 0, 0.0)


class OSSUploadAny:
    """ä¸‡èƒ½OSSä¸Šä¼ èŠ‚ç‚¹ï¼Œæ”¯æŒä»»æ„ç±»å‹è¾“å…¥"""
    
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "oss_encrypted_config": ("STRING", {
                    "multiline": False,
                    "tooltip": "åŠ å¯†çš„OSSé…ç½®å­—ç¬¦ä¸²"
                }),
                "source": (NodeIO.ANY if COMFY_TYPES_AVAILABLE else "ANY", {
                    "tooltip": "ä»»æ„ç±»å‹çš„æ•°æ®è¾“å…¥"
                }),
            },
            "optional": {
                "filename_prefix": ("STRING", {
                    "default": "comfyui",
                    "tooltip": "æ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼‰"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("url", "upload_log", "local_file_path")
    FUNCTION = "upload"
    CATEGORY = "hhy/oss"
    
    def _detect_source_type_and_save(self, source, filename_prefix="comfyui"):
        """ğŸ›¡ï¸ å®‰å…¨åœ°æ£€æµ‹è¾“å…¥æºç±»å‹å¹¶ä¿å­˜ä¸ºæ–‡ä»¶"""
        temp_file = None
        data_type = "unknown"
        
        # 1. æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
        if isinstance(source, str):
            if os.path.exists(source):
                # ğŸ›¡ï¸ éªŒè¯æ–‡ä»¶è·¯å¾„å®‰å…¨æ€§
                try:
                    perform_security_validation(source)
                    return source, "file", None
                except SecurityError as e:
                    raise SecurityError(f"ğŸš¨ æ–‡ä»¶è·¯å¾„éªŒè¯å¤±è´¥: {e}")
            else:
                # å½“ä½œæ–‡æœ¬å†…å®¹å¤„ç†
                temp_file = save_text_to_temp(source, filename_prefix, "txt")
                return temp_file, "text", temp_file
        
        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯torch.Tensorï¼ˆå›¾ç‰‡ï¼‰
        elif isinstance(source, torch.Tensor):
            if len(source.shape) >= 3:
                # å¯èƒ½æ˜¯å›¾ç‰‡å¼ é‡
                try:
                    # å¦‚æœæ˜¯æ‰¹é‡ï¼Œå–ç¬¬ä¸€å¼ 
                    if len(source.shape) == 4:
                        source = source[0]
                    temp_file = save_image_to_temp(source, filename_prefix, "png")
                    return temp_file, "image", temp_file
                except Exception:
                    # ğŸš¨ å®‰å…¨ç­–ç•¥: ç¦ç”¨pickleåºåˆ—åŒ–ï¼Œæ”¹ç”¨å®‰å…¨çš„numpyæ ¼å¼
                    temp_file = temp_manager.create_temp_file(filename_prefix, ".npz")
                    try:
                        # ä½¿ç”¨numpyçš„å®‰å…¨å‹ç¼©æ ¼å¼ä»£æ›¿pickle
                        np.savez_compressed(temp_file, data=source.cpu().numpy())
                        return temp_file, "tensor", temp_file
                    except Exception as e:
                        temp_manager.cleanup_file(temp_file)
                        raise SecurityError(f"æ— æ³•å®‰å…¨ä¿å­˜tensoræ•°æ®: {e}")
        
        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯éŸ³é¢‘å­—å…¸
        elif isinstance(source, dict) and "sample_rate" in source and "waveform" in source:
            temp_file = save_audio_to_temp(source, filename_prefix, "wav")
            return temp_file, "audio", temp_file
        
        # 4. æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘å¯¹è±¡
        elif hasattr(source, 'save_to'):
            try:
                temp_file = save_video_to_temp(source, filename_prefix, "mp4")
                return temp_file, "video", temp_file
            except Exception:
                pass
        
        # 5. æ£€æŸ¥åŸºæœ¬æ•°æ®ç±»å‹
        elif isinstance(source, (int, float, bool)):
            content = str(source)
            temp_file = save_text_to_temp(content, filename_prefix, "txt")
            return temp_file, "numeric", temp_file
        
        # 6. æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨æˆ–å­—å…¸
        elif isinstance(source, (list, dict, tuple)):
            try:
                content = json.dumps(source, indent=2, ensure_ascii=False)
                temp_file = save_text_to_temp(content, filename_prefix, "json")
                return temp_file, "json", temp_file
            except Exception:
                content = str(source)
                temp_file = save_text_to_temp(content, filename_prefix, "txt")
                return temp_file, "data", temp_file
        
        # 7. å°è¯•åºåˆ—åŒ–å…¶ä»–ç±»å‹
        else:
            try:
                # å°è¯•JSONåºåˆ—åŒ–
                content = json.dumps(source, indent=2, ensure_ascii=False)
                temp_file = save_text_to_temp(content, filename_prefix, "json")
                return temp_file, "serialized", temp_file
            except Exception:
                try:
                    # å°è¯•å­—ç¬¦ä¸²è½¬æ¢
                    content = str(source)
                    temp_file = save_text_to_temp(content, filename_prefix, "txt")
                    return temp_file, "string", temp_file
                except Exception:
                    # ğŸš¨ å®‰å…¨ç­–ç•¥: ç¦ç”¨pickleåºåˆ—åŒ–ï¼Œæ‹’ç»å¤„ç†æœªçŸ¥ç±»å‹
                    raise SecurityError(
                        f"ğŸš¨ ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(source).__name__}\n"
                        f"ä¸ºäº†å®‰å…¨ï¼Œå·²ç¦ç”¨pickleåºåˆ—åŒ–åŠŸèƒ½ã€‚\n"
                        f"æ”¯æŒçš„ç±»å‹: å­—ç¬¦ä¸²ã€å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ã€åŸºæœ¬æ•°æ®ç±»å‹ã€JSONå…¼å®¹çš„å¯¹è±¡"
                    )

    def upload(self, oss_encrypted_config, source, filename_prefix="comfyui"):
        temp_file = None
        try:
            # æ£€æµ‹æºç±»å‹å¹¶ä¿å­˜
            local_file, data_type, temp_file = self._detect_source_type_and_save(source, filename_prefix)

            # åˆå§‹åŒ–OSSå®¢æˆ·ç«¯
            self.encrypted_config = oss_encrypted_config
            _init_client(self)

            # ä¸Šä¼ æ–‡ä»¶
            result = upload_file_with_progress(self, local_file)

            # ç”ŸæˆURL
            url = result.get('presigned_url')
            if not url:
                object_name = result.get('object_name')
                if getattr(self, 'endpoint', None) and self.endpoint.startswith('http'):
                    url = f"{self.endpoint.rstrip('/')}/{object_name}"
                else:
                    url = f"https://{self.bucket_name}.oss-{self.region}.aliyuncs.com/{object_name}"

            # ç”Ÿæˆæ—¥å¿—
            log_items = [
                f"type={data_type}",
                f"source_type={type(source).__name__}",
                f"status_code={result.get('status_code')}",
                f"request_id={result.get('request_id')}",
                f"etag={result.get('etag')}",
                f"crc64={result.get('hash_crc64')}",
                f"object={result.get('object_name')}"
            ]
            upload_log = " | ".join([str(x) for x in log_items if x is not None])

            return (str(url), str(upload_log), str(local_file))
            
        except Exception as exc:
            error_msg = f"ä¸Šä¼ å¤±è´¥: {exc}"
            return ("", error_msg, temp_file or "")
        finally:
            # ä¿ç•™ä¸´æ—¶æ–‡ä»¶ä¾›ç”¨æˆ·æŸ¥çœ‹
            pass


NODE_CLASS_MAPPINGS = {
    "ResourceToFilePaths": ResourceToFilePaths,
    "OSSUploadFromPaths": OSSUploadFromPaths,
    "VideoCombineToPath": VideoCombineToPath,
    "OSSUploadAny": OSSUploadAny
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ResourceToFilePaths": "èµ„æºè½¬æ–‡ä»¶è·¯å¾„",
    "OSSUploadFromPaths": "OSS ä»è·¯å¾„ä¸Šä¼ ",
    "VideoCombineToPath": "è§†é¢‘åˆå¹¶åˆ°è·¯å¾„",
    "OSSUploadAny": "OSS ä»»æ„ä¸Šä¼ (å³å°†å¼ƒç”¨)"
}